{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe153b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55f7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "metadata = pd.read_csv('C://Users//riyac//Downloads//data//data//SPGC-metadata-2018-07-18.csv')\n",
    "kld_scores = pd.read_csv('C:/Users//riyac//Downloads//data//data//KLDscores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05283a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata info before handling null values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57713 entries, 0 to 57712\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 57713 non-null  object \n",
      " 1   title              57642 non-null  object \n",
      " 2   author             55451 non-null  object \n",
      " 3   authoryearofbirth  42946 non-null  float64\n",
      " 4   authoryearofdeath  41850 non-null  float64\n",
      " 5   language           57711 non-null  object \n",
      " 6   downloads          57711 non-null  float64\n",
      " 7   subjects           57713 non-null  object \n",
      " 8   type               57713 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 4.0+ MB\n",
      "None\n",
      "\n",
      "KLD Scores info before handling null values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23193 entries, 0 to 23192\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   filename    23193 non-null  object\n",
      " 1   kld_values  23193 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 362.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display initial information about the datasets\n",
    "print(\"Metadata info before handling null values:\")\n",
    "print(metadata.info())\n",
    "print(\"\\nKLD Scores info before handling null values:\")\n",
    "print(kld_scores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea20e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling null values in metadata\n",
    "# Drop rows where essential information (id, title) is missing\n",
    "metadata.dropna(subset=['id', 'title'], inplace=True)\n",
    "\n",
    "# Fill null values in numerical columns with their mean or median\n",
    "numerical_cols = ['authoryearofbirth', 'authoryearofdeath', 'downloads']\n",
    "for col in numerical_cols:\n",
    "    if col in metadata.columns:\n",
    "        metadata[col].fillna(metadata[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5a2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling null values in kld_scores\n",
    "# Drop rows where essential information (filename, kld_values) is missing\n",
    "kld_scores.dropna(subset=['filename', 'kld_values'], inplace=True)\n",
    "\n",
    "# Convert kld_values from string representation of list to actual list\n",
    "kld_scores['kld_values'] = kld_scores['kld_values'].apply(lambda x: eval(x) if pd.notnull(x) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ed6848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata info after handling null values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57642 entries, 1 to 57712\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 57642 non-null  object \n",
      " 1   title              57642 non-null  object \n",
      " 2   author             55451 non-null  object \n",
      " 3   authoryearofbirth  57642 non-null  float64\n",
      " 4   authoryearofdeath  57642 non-null  float64\n",
      " 5   language           57641 non-null  object \n",
      " 6   downloads          57642 non-null  float64\n",
      " 7   subjects           57642 non-null  object \n",
      " 8   type               57642 non-null  object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "\n",
      "KLD Scores info after handling null values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23193 entries, 0 to 23192\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   filename    23193 non-null  object\n",
      " 1   kld_values  23193 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 362.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display information after handling null values\n",
    "print(\"\\nMetadata info after handling null values:\")\n",
    "print(metadata.info())\n",
    "print(\"\\nKLD Scores info after handling null values:\")\n",
    "print(kld_scores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a5cca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate book-level measures\n",
    "def calculate_kld_measures(kld_values):\n",
    "    kld_array = np.array(kld_values)\n",
    "    measures = {}\n",
    "    if len(kld_array) == 0:  # Handle case with empty kld_values\n",
    "        measures['skewness_kld'] = np.nan\n",
    "        measures['kurtosis_kld'] = np.nan\n",
    "        measures['cumulative_kld'] = np.nan\n",
    "        measures['rolling_mean_kld'] = np.nan\n",
    "    else:\n",
    "        measures['skewness_kld'] = skew(kld_array)\n",
    "        measures['kurtosis_kld'] = kurtosis(kld_array)\n",
    "        measures['cumulative_kld'] = np.sum(kld_array)\n",
    "        measures['rolling_mean_kld'] = np.mean(pd.Series(kld_array).rolling(window=5, min_periods=1).mean())\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c80550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to calculate measures for each book\n",
    "kld_measures = kld_scores['kld_values'].apply(lambda x: pd.Series(calculate_kld_measures(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97dc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the new measures with the original kld_scores dataframe\n",
    "kld_scores = pd.concat([kld_scores, kld_measures], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46c6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with metadata\n",
    "metadata = metadata.merge(kld_scores, left_on='id', right_on='filename', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d528208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                              title  \\\n",
      "0           PG1  The Declaration of Independence of the United ...   \n",
      "1           PG2  The United States Bill of Rights: The Ten Orig...   \n",
      "2           PG3                John F. Kennedy's Inaugural Address   \n",
      "3           PG4  Lincoln's Gettysburg Address: Given November 1...   \n",
      "4           PG5                     The United States Constitution   \n",
      "...         ...                                                ...   \n",
      "57637   PG57710                                 A Son of the State   \n",
      "57638   PG57711  Hudson Tercentenary: An historical retrospect ...   \n",
      "57639   PG57712                                     Proses moroses   \n",
      "57640   PG57713                        The Animal Parasites of Man   \n",
      "57641  PG999999                                      Piccole anime   \n",
      "\n",
      "                                   author  authoryearofbirth  \\\n",
      "0                       Jefferson, Thomas             1743.0   \n",
      "1                           United States             1848.0   \n",
      "2      Kennedy, John F. (John Fitzgerald)             1917.0   \n",
      "3                        Lincoln, Abraham             1809.0   \n",
      "4                           United States             1848.0   \n",
      "...                                   ...                ...   \n",
      "57637       Ridge, W. Pett (William Pett)             1848.0   \n",
      "57638                  Chamberlain, Frank             1848.0   \n",
      "57639                   Gourmont, Remy de             1858.0   \n",
      "57640                     Theobald, F. V.             1848.0   \n",
      "57641                                 NaN             1848.0   \n",
      "\n",
      "       authoryearofdeath language  downloads  \\\n",
      "0                 1826.0   ['en']      604.0   \n",
      "1                 1914.0   ['en']      158.0   \n",
      "2                 1963.0   ['en']       28.0   \n",
      "3                 1865.0   ['en']       55.0   \n",
      "4                 1914.0   ['en']      226.0   \n",
      "...                  ...      ...        ...   \n",
      "57637             1930.0   ['en']        0.0   \n",
      "57638             1914.0   ['en']        0.0   \n",
      "57639             1915.0   ['fr']        0.0   \n",
      "57640             1914.0   ['en']        0.0   \n",
      "57641             1914.0      NaN       15.0   \n",
      "\n",
      "                                                subjects  type filename  \\\n",
      "0      {'United States -- History -- Revolution, 1775...  Text      NaN   \n",
      "1      {'Civil rights -- United States -- Sources', '...  Text      NaN   \n",
      "2      {'Presidents -- United States -- Inaugural add...  Text      NaN   \n",
      "3      {'Consecration of cemeteries -- Pennsylvania -...  Text      NaN   \n",
      "4      {'United States. Constitution', 'United States...  Text      NaN   \n",
      "...                                                  ...   ...      ...   \n",
      "57637                                              set()  Text  PG57710   \n",
      "57638                                              set()  Text      NaN   \n",
      "57639                                              set()  Text      NaN   \n",
      "57640                                              set()  Text  PG57713   \n",
      "57641                                              set()  Text      NaN   \n",
      "\n",
      "                                              kld_values  skewness_kld  \\\n",
      "0                                                    NaN           NaN   \n",
      "1                                                    NaN           NaN   \n",
      "2                                                    NaN           NaN   \n",
      "3                                                    NaN           NaN   \n",
      "4                                                    NaN           NaN   \n",
      "...                                                  ...           ...   \n",
      "57637  [0.25942302871143996, 0.26475610039264486, 0.2...      0.302159   \n",
      "57638                                                NaN           NaN   \n",
      "57639                                                NaN           NaN   \n",
      "57640  [0.4801571597564764, 0.23783626702059418, 0.24...      3.247238   \n",
      "57641                                                NaN           NaN   \n",
      "\n",
      "       kurtosis_kld  cumulative_kld  rolling_mean_kld  \n",
      "0               NaN             NaN               NaN  \n",
      "1               NaN             NaN               NaN  \n",
      "2               NaN             NaN               NaN  \n",
      "3               NaN             NaN               NaN  \n",
      "4               NaN             NaN               NaN  \n",
      "...             ...             ...               ...  \n",
      "57637     -0.805766       12.005082          0.246297  \n",
      "57638           NaN             NaN               NaN  \n",
      "57639           NaN             NaN               NaN  \n",
      "57640     10.763243       12.848532          0.267924  \n",
      "57641           NaN             NaN               NaN  \n",
      "\n",
      "[57642 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0dda3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert kld_values from string representation of lists to actual lists\n",
    "# def convert_to_list(x):\n",
    "#     if isinstance(x, str):\n",
    "#         return np.array(eval(x))\n",
    "#     return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5e23c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kld_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkld_values\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kld_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkld_values\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(convert_to_list)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_to_list' is not defined"
     ]
    }
   ],
   "source": [
    "kld_scores['kld_values'] = kld_scores['kld_values'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b88873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.22391005737243896, 0.24226261808703536, 0.2...\n",
       "1        [0.24107767463211327, 0.24747085497572513, 0.2...\n",
       "2        [0.2502283960399736, 0.2304129699198611, 0.238...\n",
       "3        [0.2576982842724978, 0.2424932127358288, 0.220...\n",
       "4        [0.25125974534678364, 0.23622148585532693, 0.2...\n",
       "                               ...                        \n",
       "23188    [0.22838257901564088, 0.21120893011566938, 0.2...\n",
       "23189    [0.2471592500558816, 0.1970731579466416, 0.291...\n",
       "23190    [0.21198661056119145, 0.21617505920334878, 0.2...\n",
       "23191    [0.24116003079407344, 0.21510152162479515, 0.2...\n",
       "23192    [0.20625582936128445, 0.20509986575511333, 0.1...\n",
       "Name: kld_values, Length: 23193, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kld_scores['kld_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6882518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate book-level measures\n",
    "kld_summary = kld_scores.copy()\n",
    "kld_summary['avg_KLD'] = kld_summary['kld_values'].apply(np.mean)\n",
    "kld_summary['var_KLD'] = kld_summary['kld_values'].apply(np.var)\n",
    "kld_summary['slope_KLD'] = kld_summary['kld_values'].apply(lambda x: np.polyfit(range(len(x)), x, 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc5f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate rolling statistics\n",
    "def rolling_statistics(kld_values, window=5):\n",
    "    return pd.Series(kld_values).rolling(window).mean().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b149e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness, kurtosis, cumulative KLD, and rolling statistics\n",
    "def calculate_kld_metrics(kld_scores):\n",
    "    kld_scores['skewness'] = kld_scores['kld_values'].apply(lambda x: skew(x))\n",
    "    kld_scores['kurtosis'] = kld_scores['kld_values'].apply(lambda x: kurtosis(x))\n",
    "    kld_scores['cumulative_kld'] = kld_scores['kld_values'].apply(lambda x: np.sum(x))\n",
    "    kld_scores['rolling_mean_kld'] = kld_scores['kld_values'].apply(lambda x: rolling_statistics(x, window=5))\n",
    "    return kld_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e90fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your KLD scores DataFrame\n",
    "kld_scores = calculate_kld_metrics(kld_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a161f44e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge with metadata\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(metadata, kld_summary[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_KLD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_KLD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslope_KLD\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['id'] not in index\""
     ]
    }
   ],
   "source": [
    "# # Merge with metadata\n",
    "# data = pd.merge(metadata, kld_summary[['id', 'avg_KLD', 'var_KLD', 'slope_KLD']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8ea1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with metadata (assuming 'filename' is the common key)\n",
    "full_data = kld_scores.merge(metadata, left_on='filename', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "232d5a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename                                         kld_values  skewness  \\\n",
      "0  PG10002  [0.22391005737243896, 0.24226261808703536, 0.2...  3.214062   \n",
      "1  PG10005  [0.24107767463211327, 0.24747085497572513, 0.2...  1.876079   \n",
      "2  PG10003  [0.2502283960399736, 0.2304129699198611, 0.238...  4.132600   \n",
      "3  PG10008  [0.2576982842724978, 0.2424932127358288, 0.220...  5.612184   \n",
      "4  PG10012  [0.25125974534678364, 0.23622148585532693, 0.2...  0.209351   \n",
      "\n",
      "    kurtosis  cumulative_kld  \\\n",
      "0  14.083175       11.467601   \n",
      "1   5.665046       11.924212   \n",
      "2  16.760701       11.838955   \n",
      "3  33.819186       11.767495   \n",
      "4   0.697714       11.096964   \n",
      "\n",
      "                                    rolling_mean_kld       id  \\\n",
      "0  [nan, nan, nan, nan, 0.23940459513169365, 0.23...  PG10002   \n",
      "1  [nan, nan, nan, nan, 0.23598490054014315, 0.23...  PG10005   \n",
      "2  [nan, nan, nan, nan, 0.23609171502086213, 0.22...  PG10003   \n",
      "3  [nan, nan, nan, nan, 0.23145401581378824, 0.22...  PG10008   \n",
      "4  [nan, nan, nan, nan, 0.23683499268675084, 0.23...  PG10012   \n",
      "\n",
      "                                               title                 author  \\\n",
      "0                        The House on the Borderland  Hodgson, William Hope   \n",
      "1  A Voyage to the Moon: With Some Account of the...         Tucker, George   \n",
      "2         My First Years as a Frenchwoman, 1876-1879  Waddington, Mary King   \n",
      "3                                        The Mystery  White, Stewart Edward   \n",
      "4                        The Mountains of California             Muir, John   \n",
      "\n",
      "   authoryearofbirth  authoryearofdeath language  downloads  \\\n",
      "0             1877.0             1918.0   ['en']      593.0   \n",
      "1             1775.0             1861.0   ['en']       17.0   \n",
      "2             1833.0             1923.0   ['en']       11.0   \n",
      "3             1873.0             1946.0   ['en']       47.0   \n",
      "4             1838.0             1914.0   ['en']       93.0   \n",
      "\n",
      "                                            subjects  type  \n",
      "0                                {'Science fiction'}  Text  \n",
      "1  {'Space flight to the moon -- Fiction', 'Scien...  Text  \n",
      "2  {'France -- History -- Third Republic, 1870-19...  Text  \n",
      "3                                {'Science fiction'}  Text  \n",
      "4  {'Natural history -- California', 'Mountain ec...  Text  \n"
     ]
    }
   ],
   "source": [
    "# Display the updated DataFrame with new metrics\n",
    "print(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7400b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riyac\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Adding log(downloads) to the DataFrame\n",
    "full_data['log_downloads'] = np.log(full_data['downloads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2571d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for regression\n",
    "X = full_data[['skewness', 'kurtosis', 'cumulative_kld']]  # Include other controls if available\n",
    "X = sm.add_constant(X)  # Adds a constant term to the predictors\n",
    "y = full_data['log_downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5166f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the regression\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "730def10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          log_downloads   R-squared:                         nan\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Fri, 28 Jun 2024   Prob (F-statistic):                nan\n",
      "Time:                        17:35:40   Log-Likelihood:                    nan\n",
      "No. Observations:               18988   AIC:                               nan\n",
      "Df Residuals:                   18984   BIC:                               nan\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const                 nan        nan        nan        nan         nan         nan\n",
      "skewness              nan        nan        nan        nan         nan         nan\n",
      "kurtosis              nan        nan        nan        nan         nan         nan\n",
      "cumulative_kld        nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                         184.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riyac\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1732: RuntimeWarning: invalid value encountered in subtract\n",
      "  return np.sum(weights * (model.endog - mean)**2)\n"
     ]
    }
   ],
   "source": [
    "# Display the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73005edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd073a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f0e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b4842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7408a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944ac41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010cd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9759a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load datasets\n",
    "metadata = pd.read_csv('C://Users//riyac//Downloads//data//data//SPGC-metadata-2018-07-18.csv')\n",
    "kld_scores = pd.read_csv('C:/Users//riyac//Downloads//data//data//KLDscores.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7bb83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'filename' column in kld_scores to 'id' for consistency\n",
    "kld_scores.rename(columns={'filename': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63f38438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on the 'id' column\n",
    "merged_data = pd.merge(metadata, kld_scores, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b16441b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'kld_values'],\n",
      "      dtype='object')\n",
      "(57713, 10)\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.columns)\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37cb9918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'kld_values', 'subj2_war',\n",
      "       'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance',\n",
      "       'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction',\n",
      "       'subj2_action', 'subj2_thriller', 'subj2_western', 'subj2_horror',\n",
      "       'subj2_mystery', 'subj2_crime', 'subj2_history', 'subj2_periodicals',\n",
      "       'subj2_others', 'speed', 'sentiment_avg', 'sentiment_vol', 'wordcount'],\n",
      "      dtype='object')\n",
      "(57713, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "additional_data = pd.read_csv('C://Users//riyac//Downloads//data//data//extra_controls.csv')  \n",
    "\n",
    "# Merge with existing data\n",
    "new_merged_data = pd.merge(merged_data, additional_data, on='id', how='left')\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "new_merged_data = new_merged_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(new_merged_data.columns)\n",
    "print(new_merged_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12c187fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [id, downloads]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "genre_columns = [\n",
    "    'subj2_war', 'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance', \n",
    "    'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction', 'subj2_action', \n",
    "    'subj2_thriller', 'subj2_western', 'subj2_horror', 'subj2_mystery', 'subj2_crime', \n",
    "    'subj2_history', 'subj2_periodicals', 'subj2_others'\n",
    "]\n",
    "\n",
    "# Create a mask for the rows where 'downloads' is missing\n",
    "missing_downloads_mask = new_merged_data['downloads'].isnull()\n",
    "\n",
    "# Define the function to calculate the mean downloads for the genres\n",
    "def get_genre_mean(row):\n",
    "    genres = [col for col in genre_columns if row[col] == 1]\n",
    "    if genres:\n",
    "        genre_mean = new_merged_data[new_merged_data[genres].sum(axis=1) > 0]['downloads'].mean()\n",
    "        return genre_mean\n",
    "    else:\n",
    "        return new_merged_data['downloads'].mean()\n",
    "    \n",
    "# Apply the function to rows with missing downloads\n",
    "new_merged_data.loc[missing_downloads_mask, 'downloads'] = new_merged_data[missing_downloads_mask].apply(get_genre_mean, axis=1)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(new_merged_data['downloads'].isnull().sum())\n",
    "\n",
    "# Verify the imputed values\n",
    "print(new_merged_data[missing_downloads_mask][['id', 'downloads']])\n",
    "\n",
    "# # Define the function to calculate the mean downloads for the genres\n",
    "# def get_genre_mean(row):\n",
    "#     genres = [col for col in genre_columns if row[col] == 1]\n",
    "#     if genres:\n",
    "#         genre_mean = new_merged_data[new_merged_data[genres].sum(axis=1) > 0]['downloads'].mean()\n",
    "#         return genre_mean\n",
    "#     else:\n",
    "#         return new_merged_data['downloads'].mean()\n",
    "\n",
    "# # Apply the function to rows with missing downloads\n",
    "# new_merged_data.loc[missing_downloads_mask, 'downloads'] = new_merged_data[missing_downloads_mask].apply(get_genre_mean, axis=1)\n",
    "\n",
    "# # Check for any remaining missing values\n",
    "# print(new_merged_data['downloads'].isnull().sum())\n",
    "\n",
    "# # Verify the imputed values\n",
    "# print(new_merged_data[missing_downloads_mask][['id', 'downloads']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96d306e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate KLD measures\n",
    "def calculate_kld_measures(kld_list):\n",
    "    kld_list = eval(kld_list)  # Convert string representation of list to actual list\n",
    "    skewness_kld = skew(kld_list)\n",
    "    kurtosis_kld = kurtosis(kld_list)\n",
    "    cumulative_kld = np.sum(kld_list)\n",
    "    rolling_mean_kld = pd.Series(kld_list).rolling(window=5, min_periods=1).mean().mean()\n",
    "    \n",
    "    return skewness_kld, kurtosis_kld, cumulative_kld, rolling_mean_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e912319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to calculate measures for each book\n",
    "kld_measures = new_merged_data['kld_values'].dropna().apply(lambda x: calculate_kld_measures(x)).apply(pd.Series)\n",
    "kld_measures.columns = ['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39e6b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'kld_values', 'subj2_war',\n",
      "       'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance',\n",
      "       'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction',\n",
      "       'subj2_action', 'subj2_thriller', 'subj2_western', 'subj2_horror',\n",
      "       'subj2_mystery', 'subj2_crime', 'subj2_history', 'subj2_periodicals',\n",
      "       'subj2_others', 'speed', 'sentiment_avg', 'sentiment_vol', 'wordcount',\n",
      "       'kld_values', 'kld_values', 'kld_values', 'kld_values'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the KLD measures with the merged data\n",
    "new_merged_data = pd.concat([new_merged_data, kld_measures], axis=1)\n",
    "\n",
    "print(new_merged_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f64bc00a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure all columns used in the regression are numeric\u001b[39;00m\n\u001b[0;32m      2\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloads\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskewness_kld\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkurtosis_kld\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumulative_kld\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_mean_kld\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoryearofbirth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoryearofdeath\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeed\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_avg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_vol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m merged_data_clean \u001b[38;5;241m=\u001b[39m new_merged_data[numeric_cols]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld'] not in index\""
     ]
    }
   ],
   "source": [
    "# Ensure all columns used in the regression are numeric\n",
    "numeric_cols = ['downloads', 'skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', 'authoryearofbirth', 'authoryearofdeath','speed','sentiment_avg', 'sentiment_vol', 'wordcount']\n",
    "merged_data_clean = new_merged_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3a404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62750cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop rows with any NaN values in the columns of interest\n",
    "# merged_data_clean = merged_data_clean.dropna() \n",
    "\n",
    "\n",
    "# merge missing download data with mean genre download value for the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2326e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the 'downloads' column\n",
    "merged_data_clean['log_downloads'] = np.log(merged_data_clean['downloads'] + 1)  # Adding 1 to avoid log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d76f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14478, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b661b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the dependent variable and independent variables\n",
    "y = merged_data_clean['log_downloads']\n",
    "X = merged_data_clean[['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', 'authoryearofbirth', 'authoryearofdeath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61941db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert categorical variable 'language' to dummy variables\n",
    "# language_dummies = pd.get_dummies(merged_data_clean['language'].apply(lambda x: x[0] if isinstance(x, list) else x), drop_first=True)\n",
    "# X = pd.concat([X, language_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf21f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ec3cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of X before conversion:\n",
      "const                float64\n",
      "skewness_kld         float64\n",
      "kurtosis_kld         float64\n",
      "cumulative_kld       float64\n",
      "rolling_mean_kld     float64\n",
      "authoryearofbirth    float64\n",
      "authoryearofdeath    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric columns in X\n",
    "print(\"Data types of X before conversion:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eedfcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numeric (if any are object type)\n",
    "X = X.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c517b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of X after conversion:\n",
      "const                float64\n",
      "skewness_kld         float64\n",
      "kurtosis_kld         float64\n",
      "cumulative_kld       float64\n",
      "rolling_mean_kld     float64\n",
      "authoryearofbirth    float64\n",
      "authoryearofdeath    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining non-numeric columns\n",
    "print(\"Data types of X after conversion:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13348b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values that may have been introduced during conversion\n",
    "X = X.dropna()\n",
    "# Ensure y matches the index of X after cleaning\n",
    "y = y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8c9c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     const  skewness_kld  kurtosis_kld  cumulative_kld  rolling_mean_kld  \\\n",
      "100    1.0      0.317161      0.013578       11.963364          0.246172   \n",
      "102    1.0      1.397116      2.060044       13.668580          0.276907   \n",
      "105    1.0      1.508529      3.563027       11.227382          0.227560   \n",
      "106    1.0      1.671049      4.457829       11.352629          0.231256   \n",
      "107    1.0      0.596233     -0.053075       11.220667          0.228607   \n",
      "\n",
      "     authoryearofbirth  authoryearofdeath  \n",
      "100             1564.0             1616.0  \n",
      "102             1835.0             1910.0  \n",
      "105             1775.0             1817.0  \n",
      "106             1875.0             1950.0  \n",
      "107             1840.0             1928.0  \n",
      "100    8.229778\n",
      "102    6.519147\n",
      "105    7.929846\n",
      "106    5.420535\n",
      "107    6.320768\n",
      "Name: log_downloads, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of X and y to verify\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f2cbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d16ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          log_downloads   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                     92.99\n",
      "Date:                Mon, 01 Jul 2024   Prob (F-statistic):          4.80e-115\n",
      "Time:                        11:55:55   Log-Likelihood:                -21745.\n",
      "No. Observations:               14478   AIC:                         4.350e+04\n",
      "Df Residuals:                   14471   BIC:                         4.356e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 5.2682      0.175     30.034      0.000       4.924       5.612\n",
      "skewness_kld         -0.0897      0.031     -2.903      0.004      -0.150      -0.029\n",
      "kurtosis_kld          0.0103      0.005      2.084      0.037       0.001       0.020\n",
      "cumulative_kld       -0.7172      0.103     -6.953      0.000      -0.919      -0.515\n",
      "rolling_mean_kld     36.4224      5.118      7.116      0.000      26.390      46.455\n",
      "authoryearofbirth     0.0027      0.001      3.816      0.000       0.001       0.004\n",
      "authoryearofdeath    -0.0037      0.001     -5.315      0.000      -0.005      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     2252.900   Durbin-Watson:                   1.638\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4643.265\n",
      "Skew:                           0.942   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.036   Cond. No.                     1.50e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.5e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Print the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eda8827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'kld_values',\n",
      "       'skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld',\n",
      "       'subj2_war', 'subj2_adventure', 'subj2_comedy', 'subj2_biography',\n",
      "       'subj2_romance', 'subj2_drama', 'subj2_fantasy', 'subj2_family',\n",
      "       'subj2_sciencefiction', 'subj2_action', 'subj2_thriller',\n",
      "       'subj2_western', 'subj2_horror', 'subj2_mystery', 'subj2_crime',\n",
      "       'subj2_history', 'subj2_periodicals', 'subj2_others', 'speed',\n",
      "       'sentiment_avg', 'sentiment_vol', 'wordcount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "additional_data = pd.read_csv('C://Users//riyac//Downloads//data//data//extra_controls.csv')  \n",
    "\n",
    "# Merge with existing data\n",
    "new_merged_data = pd.merge(merged_data, additional_data, on='id', how='left')\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "new_merged_data = new_merged_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(new_merged_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18abdc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Log-transform the 'downloads' column\n",
    "new_merged_data['log_downloads'] = np.log(new_merged_data['downloads'] + 1)  # Adding 1 to avoid log(0)\n",
    "\n",
    "X = new_merged_data[['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', \n",
    "                 'authoryearofbirth', 'authoryearofdeath', 'speed', 'sentiment_avg', \n",
    "                 'sentiment_vol', 'wordcount'] + [col for col in new_merged_data.columns if col.startswith('subj2_')]]\n",
    "X = sm.add_constant(X)  # Add constant term\n",
    "y = new_merged_data['log_downloads']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f912c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inf or NaN values in X and handle them\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Ensure y matches the index of X\n",
    "y = y[X.index]\n",
    "\n",
    "#impute to average value of downloads genrewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03fa09bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          log_downloads   R-squared:                       0.167\n",
      "Model:                            OLS   Adj. R-squared:                  0.164\n",
      "Method:                 Least Squares   F-statistic:                     54.77\n",
      "Date:                Mon, 01 Jul 2024   Prob (F-statistic):          5.64e-258\n",
      "Time:                        13:01:05   Log-Likelihood:                -10366.\n",
      "No. Observations:                7134   AIC:                         2.079e+04\n",
      "Df Residuals:                    7107   BIC:                         2.097e+04\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    6.7752      0.347     19.520      0.000       6.095       7.456\n",
      "skewness_kld            -0.1372      0.046     -2.976      0.003      -0.228      -0.047\n",
      "kurtosis_kld             0.0164      0.007      2.274      0.023       0.002       0.031\n",
      "cumulative_kld          -1.0960      0.180     -6.075      0.000      -1.450      -0.742\n",
      "rolling_mean_kld        55.8225      8.953      6.235      0.000      38.272      73.373\n",
      "authoryearofbirth        0.0035      0.001      3.626      0.000       0.002       0.005\n",
      "authoryearofdeath       -0.0047      0.001     -4.858      0.000      -0.007      -0.003\n",
      "speed                   -3.6888      0.870     -4.238      0.000      -5.395      -1.983\n",
      "sentiment_avg           -7.2577      0.638    -11.367      0.000      -8.509      -6.006\n",
      "sentiment_vol           78.4496     11.001      7.131      0.000      56.884     100.015\n",
      "wordcount             6.039e-07   2.54e-07      2.377      0.017    1.06e-07     1.1e-06\n",
      "subj2_war               -0.1688      0.056     -2.988      0.003      -0.280      -0.058\n",
      "subj2_adventure         -0.2099      0.059     -3.528      0.000      -0.326      -0.093\n",
      "subj2_comedy          5.312e-11   8.49e-12      6.256      0.000    3.65e-11    6.98e-11\n",
      "subj2_biography         -0.1763      0.170     -1.036      0.300      -0.510       0.157\n",
      "subj2_romance            0.1436      0.068      2.112      0.035       0.010       0.277\n",
      "subj2_drama              0.0143      0.291      0.049      0.961      -0.556       0.584\n",
      "subj2_fantasy            0.9289      0.109      8.533      0.000       0.716       1.142\n",
      "subj2_family             0.0832      0.109      0.763      0.445      -0.130       0.297\n",
      "subj2_sciencefiction     0.9148      0.094      9.693      0.000       0.730       1.100\n",
      "subj2_action            -0.5353      1.039     -0.515      0.606      -2.573       1.502\n",
      "subj2_thriller        6.591e-12   1.07e-12      6.152      0.000    4.49e-12    8.69e-12\n",
      "subj2_western           -0.0383      0.086     -0.446      0.656      -0.207       0.130\n",
      "subj2_horror             1.4906      0.170      8.772      0.000       1.157       1.824\n",
      "subj2_mystery            0.1750      0.076      2.308      0.021       0.026       0.324\n",
      "subj2_crime              0.1389      0.227      0.613      0.540      -0.305       0.583\n",
      "subj2_history           -0.0745      0.056     -1.340      0.180      -0.183       0.034\n",
      "subj2_periodicals        2.8292      1.038      2.725      0.006       0.794       4.864\n",
      "subj2_others            -0.3127      0.059     -5.289      0.000      -0.429      -0.197\n",
      "==============================================================================\n",
      "Omnibus:                     1339.415   Durbin-Watson:                   1.529\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3237.615\n",
      "Skew:                           1.048   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.549   Cond. No.                     1.26e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.63e-19. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Fit the OLS regression model\n",
    "model_with_additional_data = sm.OLS(y, X).fit()\n",
    "print(model_with_additional_data.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2903ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Coefficients:\n",
      "const                   0.000000\n",
      "skewness_kld           -0.110706\n",
      "kurtosis_kld           -0.000000\n",
      "cumulative_kld         -0.000000\n",
      "rolling_mean_kld        0.000000\n",
      "authoryearofbirth      -0.000000\n",
      "authoryearofdeath      -0.132805\n",
      "speed                  -0.077627\n",
      "sentiment_avg          -0.141678\n",
      "sentiment_vol           0.140141\n",
      "wordcount               0.045047\n",
      "subj2_war              -0.018928\n",
      "subj2_adventure        -0.024160\n",
      "subj2_comedy            0.000000\n",
      "subj2_biography        -0.000000\n",
      "subj2_romance           0.026423\n",
      "subj2_drama             0.000000\n",
      "subj2_fantasy           0.106527\n",
      "subj2_family            0.000482\n",
      "subj2_sciencefiction    0.136933\n",
      "subj2_action           -0.000000\n",
      "subj2_thriller          0.000000\n",
      "subj2_western           0.000000\n",
      "subj2_horror            0.103583\n",
      "subj2_mystery           0.037017\n",
      "subj2_crime             0.000000\n",
      "subj2_history          -0.000000\n",
      "subj2_periodicals       0.018021\n",
      "subj2_others           -0.113777\n",
      "dtype: float64\n",
      "Important Predictors identified by LASSO:\n",
      "['skewness_kld', 'authoryearofdeath', 'speed', 'sentiment_avg', 'sentiment_vol', 'wordcount', 'subj2_war', 'subj2_adventure', 'subj2_romance', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction', 'subj2_horror', 'subj2_mystery', 'subj2_periodicals', 'subj2_others']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform LASSO regression with cross-validation\n",
    "lasso = LassoCV(cv=5).fit(X_scaled, y)\n",
    "lasso_coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
    "\n",
    "print(\"LASSO Coefficients:\")\n",
    "print(lasso_coefficients)\n",
    "\n",
    "# Identify important predictors\n",
    "important_predictors = lasso_coefficients[lasso_coefficients != 0].index.tolist()\n",
    "print(\"Important Predictors identified by LASSO:\")\n",
    "print(important_predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260eb058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda52947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b978e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87043560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71decfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bcdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccc827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235b628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e0e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e14a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439fd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "metadata = pd.read_csv('C://Users//riyac//Downloads//data//data//SPGC-metadata-2018-07-18.csv')\n",
    "kld_scores = pd.read_csv('C:/Users//riyac//Downloads//data//data//KLDscores.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38b03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'filename' column in kld_scores to 'id' for consistency\n",
    "kld_scores.rename(columns={'filename': 'id'}, inplace=True)\n",
    "# Merge datasets on the 'id' column\n",
    "merged_data = pd.merge(metadata, kld_scores, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd5ebc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the new dataset\n",
    "# additional_data = pd.read_csv('C://Users//riyac//Downloads//data//data//extra_controls.csv')  \n",
    "\n",
    "# # Merge with existing data\n",
    "# new_merged_data = pd.merge(merged_data, additional_data, on='id', how='left')\n",
    "\n",
    "# # Ensure all columns are numeric\n",
    "# new_merged_data = new_merged_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33ddd740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "       id  downloads\n",
      "0     NaN  50.717194\n",
      "57712 NaN  50.717194\n"
     ]
    }
   ],
   "source": [
    "# genre_columns = [\n",
    "#     'subj2_war', 'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance', \n",
    "#     'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction', 'subj2_action', \n",
    "#     'subj2_thriller', 'subj2_western', 'subj2_horror', 'subj2_mystery', 'subj2_crime', \n",
    "#     'subj2_history', 'subj2_periodicals', 'subj2_others'\n",
    "# ]\n",
    "\n",
    "# # Create a mask for the rows where 'downloads' is missing\n",
    "# missing_downloads_mask = new_merged_data['downloads'].isnull()\n",
    "\n",
    "# # Define the function to calculate the mean downloads for the genres\n",
    "# def get_genre_mean(row):\n",
    "#     genres = [col for col in genre_columns if row[col] == 1]\n",
    "#     if genres:\n",
    "#         genre_mean = new_merged_data[new_merged_data[genres].sum(axis=1) > 0]['downloads'].mean()\n",
    "#         return genre_mean\n",
    "#     else:\n",
    "#         return new_merged_data['downloads'].mean()\n",
    "\n",
    "# # Apply the function to rows with missing downloads\n",
    "# new_merged_data.loc[missing_downloads_mask, 'downloads'] = new_merged_data[missing_downloads_mask].apply(get_genre_mean, axis=1)\n",
    "\n",
    "# # Check for any remaining missing values\n",
    "# print(new_merged_data['downloads'].isnull().sum())\n",
    "\n",
    "# # Verify the imputed values\n",
    "# print(new_merged_data[missing_downloads_mask][['id', 'downloads']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77d75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate KLD measures\n",
    "def calculate_kld_measures(kld_list):\n",
    "    kld_list = eval(kld_list)  # Convert string representation of list to actual list\n",
    "    skewness_kld = skew(kld_list)\n",
    "    kurtosis_kld = kurtosis(kld_list)\n",
    "    cumulative_kld = np.sum(kld_list)\n",
    "    rolling_mean_kld = pd.Series(kld_list).rolling(window=5, min_periods=1).mean().mean()\n",
    "    \n",
    "    return skewness_kld, kurtosis_kld, cumulative_kld, rolling_mean_kld\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df548ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to calculate measures for each book\n",
    "kld_measures = merged_data['kld_values'].dropna().apply(lambda x: calculate_kld_measures(x)).apply(pd.Series)\n",
    "kld_measures.columns = ['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35bd0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the repeated 'kld_values' column to avoid conflicts\n",
    "merged_data.drop(columns=['kld_values'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4ab9f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'skewness_kld',\n",
      "       'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the new measures with the original DataFrame\n",
    "merged_data = pd.concat([merged_data, kld_measures], axis=1)\n",
    "\n",
    "# Display the updated DataFrame with new metrics\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Drop duplicate 'kld_values' columns\n",
    "merged_data = merged_data.loc[:, ~merged_data.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfd7f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all columns used in the regression are numeric\n",
    "numeric_cols = ['downloads', 'skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', 'authoryearofbirth', 'authoryearofdeath']\n",
    "merged_data_clean = merged_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b75c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'authoryearofbirth', 'authoryearofdeath',\n",
      "       'language', 'downloads', 'subjects', 'type', 'skewness_kld',\n",
      "       'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', 'subj2_war',\n",
      "       'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance',\n",
      "       'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction',\n",
      "       'subj2_action', 'subj2_thriller', 'subj2_western', 'subj2_horror',\n",
      "       'subj2_mystery', 'subj2_crime', 'subj2_history', 'subj2_periodicals',\n",
      "       'subj2_others', 'speed', 'sentiment_avg', 'sentiment_vol', 'wordcount'],\n",
      "      dtype='object')\n",
      "(57713, 35)\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "additional_data = pd.read_csv('C://Users//riyac//Downloads//data//data//extra_controls.csv')  \n",
    "\n",
    "# Merge with existing data\n",
    "new_merged_data = pd.merge(merged_data, additional_data, on='id', how='left')\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "new_merged_data = new_merged_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(new_merged_data.columns)\n",
    "print(new_merged_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b51bdd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "       id  downloads\n",
      "0     NaN  50.717194\n",
      "57712 NaN  50.717194\n"
     ]
    }
   ],
   "source": [
    "genre_columns = [\n",
    "    'subj2_war', 'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance', \n",
    "    'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction', 'subj2_action', \n",
    "    'subj2_thriller', 'subj2_western', 'subj2_horror', 'subj2_mystery', 'subj2_crime', \n",
    "    'subj2_history', 'subj2_periodicals', 'subj2_others'\n",
    "]\n",
    "\n",
    "# Create a mask for the rows where 'downloads' is missing\n",
    "missing_downloads_mask = new_merged_data['downloads'].isnull()\n",
    "\n",
    "# Define the function to calculate the mean downloads for the genres\n",
    "def get_genre_mean(row):\n",
    "    genres = [col for col in genre_columns if row[col] == 1]\n",
    "    if genres:\n",
    "        genre_mean = new_merged_data[new_merged_data[genres].sum(axis=1) > 0]['downloads'].mean()\n",
    "        return genre_mean\n",
    "    else:\n",
    "        return new_merged_data['downloads'].mean()\n",
    "\n",
    "# Apply the function to rows with missing downloads\n",
    "new_merged_data.loc[missing_downloads_mask, 'downloads'] = new_merged_data[missing_downloads_mask].apply(get_genre_mean, axis=1)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(new_merged_data['downloads'].isnull().sum())\n",
    "\n",
    "# Verify the imputed values\n",
    "print(new_merged_data[missing_downloads_mask][['id', 'downloads']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da37d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Log-transform the 'downloads' column\n",
    "new_merged_data['log_downloads'] = np.log(new_merged_data['downloads'] + 1)  # Adding 1 to avoid log(0)\n",
    "\n",
    "X = new_merged_data[['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', \n",
    "                 'authoryearofbirth', 'authoryearofdeath', 'speed', 'sentiment_avg', \n",
    "                 'sentiment_vol', 'wordcount'] + [col for col in new_merged_data.columns if col.startswith('subj2_')]]\n",
    "X = sm.add_constant(X)  # Add constant term\n",
    "y = new_merged_data['log_downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24baabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inf or NaN values in X and handle them\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Ensure y matches the index of X\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "739c3873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          log_downloads   R-squared:                       0.167\n",
      "Model:                            OLS   Adj. R-squared:                  0.164\n",
      "Method:                 Least Squares   F-statistic:                     54.77\n",
      "Date:                Mon, 01 Jul 2024   Prob (F-statistic):          5.64e-258\n",
      "Time:                        22:11:05   Log-Likelihood:                -10366.\n",
      "No. Observations:                7134   AIC:                         2.079e+04\n",
      "Df Residuals:                    7107   BIC:                         2.097e+04\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    6.7752      0.347     19.520      0.000       6.095       7.456\n",
      "skewness_kld            -0.1372      0.046     -2.976      0.003      -0.228      -0.047\n",
      "kurtosis_kld             0.0164      0.007      2.274      0.023       0.002       0.031\n",
      "cumulative_kld          -1.0960      0.180     -6.075      0.000      -1.450      -0.742\n",
      "rolling_mean_kld        55.8225      8.953      6.235      0.000      38.272      73.373\n",
      "authoryearofbirth        0.0035      0.001      3.626      0.000       0.002       0.005\n",
      "authoryearofdeath       -0.0047      0.001     -4.858      0.000      -0.007      -0.003\n",
      "speed                   -3.6888      0.870     -4.238      0.000      -5.395      -1.983\n",
      "sentiment_avg           -7.2577      0.638    -11.367      0.000      -8.509      -6.006\n",
      "sentiment_vol           78.4496     11.001      7.131      0.000      56.884     100.015\n",
      "wordcount             6.039e-07   2.54e-07      2.377      0.017    1.06e-07     1.1e-06\n",
      "subj2_war               -0.1688      0.056     -2.988      0.003      -0.280      -0.058\n",
      "subj2_adventure         -0.2099      0.059     -3.528      0.000      -0.326      -0.093\n",
      "subj2_comedy          5.312e-11   8.49e-12      6.256      0.000    3.65e-11    6.98e-11\n",
      "subj2_biography         -0.1763      0.170     -1.036      0.300      -0.510       0.157\n",
      "subj2_romance            0.1436      0.068      2.112      0.035       0.010       0.277\n",
      "subj2_drama              0.0143      0.291      0.049      0.961      -0.556       0.584\n",
      "subj2_fantasy            0.9289      0.109      8.533      0.000       0.716       1.142\n",
      "subj2_family             0.0832      0.109      0.763      0.445      -0.130       0.297\n",
      "subj2_sciencefiction     0.9148      0.094      9.693      0.000       0.730       1.100\n",
      "subj2_action            -0.5353      1.039     -0.515      0.606      -2.573       1.502\n",
      "subj2_thriller        6.591e-12   1.07e-12      6.152      0.000    4.49e-12    8.69e-12\n",
      "subj2_western           -0.0383      0.086     -0.446      0.656      -0.207       0.130\n",
      "subj2_horror             1.4906      0.170      8.772      0.000       1.157       1.824\n",
      "subj2_mystery            0.1750      0.076      2.308      0.021       0.026       0.324\n",
      "subj2_crime              0.1389      0.227      0.613      0.540      -0.305       0.583\n",
      "subj2_history           -0.0745      0.056     -1.340      0.180      -0.183       0.034\n",
      "subj2_periodicals        2.8292      1.038      2.725      0.006       0.794       4.864\n",
      "subj2_others            -0.3127      0.059     -5.289      0.000      -0.429      -0.197\n",
      "==============================================================================\n",
      "Omnibus:                     1339.415   Durbin-Watson:                   1.529\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3237.615\n",
      "Skew:                           1.048   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.549   Cond. No.                     1.26e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.63e-19. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Fit the OLS regression model\n",
    "model_with_additional_data = sm.OLS(y, X).fit()\n",
    "print(model_with_additional_data.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01592d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "columns_to_remove = ['authoryearofbirth', 'authoryearofdeath', 'wordcount','type','subj2_war', 'subj2_adventure', 'subj2_comedy', 'subj2_biography', 'subj2_romance', \n",
    "    'subj2_drama', 'subj2_fantasy', 'subj2_family', 'subj2_sciencefiction', 'subj2_action', \n",
    "    'subj2_thriller', 'subj2_western', 'subj2_horror', 'subj2_mystery', 'subj2_crime', \n",
    "    'subj2_history', 'subj2_periodicals', 'subj2_others']\n",
    "data_for_model = new_merged_data.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480c0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bddfcf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'author', 'language', 'downloads', 'subjects',\n",
      "       'skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld',\n",
      "       'speed', 'sentiment_avg', 'sentiment_vol', 'log_downloads'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_for_model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "795686c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_for_model[['skewness_kld', 'kurtosis_kld', 'cumulative_kld', 'rolling_mean_kld', \n",
    "                 'speed', 'sentiment_avg', 'sentiment_vol']]\n",
    "X = sm.add_constant(X)  # Add constant term\n",
    "\n",
    "# Ensure y matches the index of X\n",
    "y = data_for_model['log_downloads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05dd685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for inf or NaN values in X and handle them\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Ensure y matches the index of X\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6caea562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          log_downloads   R-squared:                       0.084\n",
      "Model:                            OLS   Adj. R-squared:                  0.083\n",
      "Method:                 Least Squares   F-statistic:                     111.4\n",
      "Date:                Mon, 01 Jul 2024   Prob (F-statistic):          6.17e-157\n",
      "Time:                        22:26:39   Log-Likelihood:                -12741.\n",
      "No. Observations:                8534   AIC:                         2.550e+04\n",
      "Df Residuals:                    8526   BIC:                         2.555e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                4.2951      0.244     17.630      0.000       3.818       4.773\n",
      "skewness_kld        -0.1056      0.044     -2.403      0.016      -0.192      -0.019\n",
      "kurtosis_kld         0.0108      0.007      1.570      0.116      -0.003       0.024\n",
      "cumulative_kld      -1.0532      0.169     -6.214      0.000      -1.385      -0.721\n",
      "rolling_mean_kld    53.9194      8.401      6.418      0.000      37.451      70.387\n",
      "speed               -4.3381      0.792     -5.480      0.000      -5.890      -2.786\n",
      "sentiment_avg       -9.1505      0.557    -16.442      0.000     -10.241      -8.060\n",
      "sentiment_vol      102.3627      8.407     12.175      0.000      85.882     118.843\n",
      "==============================================================================\n",
      "Omnibus:                     1653.220   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3892.383\n",
      "Skew:                           1.091   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.488   Cond. No.                     1.07e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.07e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Fit the OLS regression model\n",
    "model_with_additional_data = sm.OLS(y, X).fit()\n",
    "print(model_with_additional_data.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b31fbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Coefficients:\n",
      "const               0.000000\n",
      "skewness_kld       -0.114902\n",
      "kurtosis_kld       -0.000000\n",
      "cumulative_kld     -0.000000\n",
      "rolling_mean_kld    0.007440\n",
      "speed              -0.101239\n",
      "sentiment_avg      -0.203645\n",
      "sentiment_vol       0.202774\n",
      "dtype: float64\n",
      "Important Predictors identified by LASSO:\n",
      "['skewness_kld', 'rolling_mean_kld', 'speed', 'sentiment_avg', 'sentiment_vol']\n"
     ]
    }
   ],
   "source": [
    "#LASSO Regularization\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform LASSO regression with cross-validation\n",
    "lasso = LassoCV(cv=5).fit(X_scaled, y)\n",
    "lasso_coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
    "\n",
    "print(\"LASSO Coefficients:\")\n",
    "print(lasso_coefficients)\n",
    "\n",
    "# Identify important predictors\n",
    "important_predictors = lasso_coefficients[lasso_coefficients != 0].index.tolist()\n",
    "print(\"Important Predictors identified by LASSO:\")\n",
    "print(important_predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a4468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
